{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(device(type='cpu'), <torch.cuda.device at 0x1f6daeb9520>)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "torch.device('cpu'), torch.cuda.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(device(type='cuda', index=0),\n device(type='cpu'),\n [device(type='cuda', index=0)])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\r\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\r\n",
    "    if torch.cuda.device_count() >= i + 1:\r\n",
    "        return torch.device(f'cuda:{i}')\r\n",
    "    return torch.device('cpu')\r\n",
    "\r\n",
    "def try_all_gpus():  #@save\r\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\r\n",
    "    devices = [\r\n",
    "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\r\n",
    "    return devices if devices else [torch.device('cpu')]\r\n",
    "\r\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,3)\r\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.]], device='cuda:0')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2,3), device= try_gpu())\r\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.5044, 0.6107, 0.9152],\n         [0.5963, 0.0152, 0.8250]]),\n tensor([[0.5044, 0.6107, 0.9152],\n         [0.5963, 0.0152, 0.8250]], device='cuda:0'))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand((2,3), device=torch.device('cpu'))\r\n",
    "Z = Y.cuda(0)\r\n",
    "Y,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.5044, 1.6107, 1.9152],\n        [1.5963, 1.0152, 1.8250]], device='cuda:0')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks and GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(3,1))\r\n",
    "net = net.to(device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.7774],\n        [0.7774]], device='cuda:0', grad_fn=<AddmmBackward>)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(10000,10000)\r\n",
    "b = torch.rand(10000,10000)\r\n",
    "c = a.cuda()\r\n",
    "d = b.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2481.7397, 2481.9324, 2497.2939,  ..., 2483.4275, 2477.1274,\n         2518.6218],\n        [2486.5198, 2507.1538, 2521.2373,  ..., 2495.8093, 2486.5549,\n         2537.0662],\n        [2486.8848, 2486.8499, 2501.4480,  ..., 2470.7163, 2478.9766,\n         2511.6184],\n        ...,\n        [2462.7896, 2475.8093, 2513.0396,  ..., 2483.8140, 2473.3503,\n         2512.2256],\n        [2500.4404, 2499.7024, 2524.7837,  ..., 2521.6809, 2507.0811,\n         2545.5786],\n        [2463.9336, 2491.6150, 2501.5088,  ..., 2488.1877, 2481.8447,\n         2506.7900]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2481.7415, 2481.9312, 2497.2910,  ..., 2483.4246, 2477.1252,\n         2518.6218],\n        [2486.5132, 2507.1541, 2521.2378,  ..., 2495.8098, 2486.5542,\n         2537.0640],\n        [2486.8840, 2486.8499, 2501.4517,  ..., 2470.7119, 2478.9736,\n         2511.6262],\n        ...,\n        [2462.7922, 2475.8096, 2513.0398,  ..., 2483.8115, 2473.3455,\n         2512.2300],\n        [2500.4443, 2499.7056, 2524.7827,  ..., 2521.6807, 2507.0793,\n         2545.5791],\n        [2463.9331, 2491.6121, 2501.5088,  ..., 2488.1863, 2481.8420,\n         2506.7939]], device='cuda:0')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2  ('venv': venv)",
   "name": "pythonjvsc74a57bd0fd6d8b48720ee3455ab3ec1a10ac8371a015782a63fd20fa01169a0d41652e74"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "fd6d8b48720ee3455ab3ec1a10ac8371a015782a63fd20fa01169a0d41652e74"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}