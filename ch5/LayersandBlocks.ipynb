{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers and Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.2953, -0.0544, -0.0325, -0.1741, -0.2114,  0.0400, -0.0546,  0.2308,\n         -0.0946,  0.0859],\n        [ 0.3654, -0.0045, -0.1742, -0.2506, -0.0385,  0.1261, -0.0493,  0.3270,\n         -0.0750,  0.2002]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.nn import functional as F\r\n",
    "\r\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\r\n",
    "\r\n",
    "X = torch.rand(2, 20)\r\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Custom Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.hidden = nn.Linear(20,256)\r\n",
    "        self.out = nn.Linear(256,10)\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        x = self.hidden(X)\r\n",
    "        x = F.relu(x)\r\n",
    "        out = self.out(x)\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0468, -0.0199, -0.0095,  0.0778, -0.2067, -0.0272, -0.1152,  0.0278,\n         -0.3658,  0.0542],\n        [ 0.0241, -0.0958,  0.1100,  0.0662, -0.1539, -0.0830, -0.0024, -0.0107,\n         -0.2227,  0.0725]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\r\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\r\n",
    "    def __init__(self, *args):\r\n",
    "        super().__init__()\r\n",
    "        for idx, arg in enumerate(args):\r\n",
    "            self._modules[str(idx)] = arg\r\n",
    "        \r\n",
    "    def forward(self, X):\r\n",
    "        for k,v in self._modules.items():\r\n",
    "            X = v(X)\r\n",
    "        return X\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0513,  0.0978,  0.1923,  0.1167,  0.2786, -0.0286,  0.0760,  0.0567,\n          0.1060, -0.1365],\n        [ 0.1034,  0.0460,  0.2194,  0.0364,  0.0870,  0.0970,  0.0172,  0.0426,\n          0.0149, -0.2083]], grad_fn=<AddmmBackward>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\r\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Code in the Forward Propagation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.rand_weight = torch.rand((20,20), requires_grad=False)\r\n",
    "        self.linear = nn.Linear(20,20)\r\n",
    "\r\n",
    "    def forward(self,X):\r\n",
    "        X = self.linear(X)\r\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\r\n",
    "        X = self.linear(X)\r\n",
    "\r\n",
    "        while X.abs().sum() > 1:\r\n",
    "            X /=2\r\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.2528, grad_fn=<SumBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\r\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.0679, grad_fn=<SumBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.net = nn.Sequential(nn.Linear(20,64), nn.ReLU(), nn.Linear(64,32), nn.ReLU())\r\n",
    "        self.linear = nn.Linear(32,16)\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        return self.linear(self.net(X))\r\n",
    "        \r\n",
    "net = nn.Sequential(NestMLP(), nn.Linear(16,20), FixedHiddenMLP())\r\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 40])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConcatMLP(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.net1 = nn.Sequential(nn.Linear(20, 20), nn.ReLU())\r\n",
    "        self.net2 = nn.Sequential(nn.Linear(20, 40), nn.ReLU(), nn.Linear(40,20), nn.ReLU())\r\n",
    "        \r\n",
    "    def forward(self, X):\r\n",
    "        return torch.cat((self.net1(X), self.net2(X)),1)\r\n",
    "\r\n",
    "net = ConcatMLP()\r\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 30])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NConcatMLP(nn.Module):\r\n",
    "    def __init__(self, n=1):\r\n",
    "        super().__init__()\r\n",
    "        for i in range(n):\r\n",
    "            self._modules[str(i)] = nn.Sequential( nn.Linear(20,20), nn.ReLU(), nn.Linear(20,10),nn.ReLU())\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        out = None\r\n",
    "        for module in self._modules.values():\r\n",
    "            if out is None:\r\n",
    "                out = module(X)\r\n",
    "            else:\r\n",
    "                out = torch.cat((out, module(X)),1)\r\n",
    "        \r\n",
    "        return out\r\n",
    "\r\n",
    "net = NConcatMLP(n=3)\r\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NConcatMLP(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2  ('venv': venv)",
   "name": "pythonjvsc74a57bd0fd6d8b48720ee3455ab3ec1a10ac8371a015782a63fd20fa01169a0d41652e74"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "fd6d8b48720ee3455ab3ec1a10ac8371a015782a63fd20fa01169a0d41652e74"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}